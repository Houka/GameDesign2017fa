<html>
<head>
<!-- Load the d3 library. -->
<script src="http://d3js.org/d3.v4.min.js" charset="utf-8"></script>
<link href='http://fonts.googleapis.com/css?family=Open+Sans' rel='stylesheet' type='text/css'>
<style>
body { font-family: "Open Sans"; }
svg { border: solid black 1px; margin: 25px; padding: 20px; }
.axis path { fill: none; stroke: black;}
.axis line { stroke: black; }
.axis text { font-size: x-small; }
</style>
</head>
<body>

<div>Name: Katherine Tang</div>
<div>netid: kat86</div>

<div>Answer any free-response questions here.

<p>c. In general, the permutation test value is very close to the t-test p-value. They are usually less than 0.1 apart.</p>

<p>f. As shown in the second graph, the two tests are very similar and thus correlate well with the line from (0, 0) to (0.5, 0.5). Since this line has a slope of 1, which represents when the permutation test value and the t-test p-values are equal, most of the points are distributed closely around it. Changing the parameters in the generateLinear function shows that as n increases, the parameters become lower and closer to one another. A steeper slope results in the points being distributed closer towards the origin and each other. Similarly, reducing noise results in the two tests closer in value while being centered more around the origin while increasing the noise causes the points to becomes slightly more spread out on the first graph. When there is no relationship, there isn't any noticeable change between the difference of the two tests.</p>

<p>g. When the slope = 0.02 and noise = 0.3, approxiamately 1100 points needed to be generated until the p-values were consistently less than 0.05. Meanwhile it took about 5 points when the slope = 0.2 and noise = 0.3 for the p-values not to be less than 0.05 consistently.</p>

<p>h. For 10 data points, there are P(10, 10) = 10!/(10-10)! = 3628800 permutations in total, making the 200 sampled just a mere fraction of all the possibilities. Lowering the number of permutations decreases the closeness of the p-values and permutation results from before, while increasing permutations also increases the closeness between the two tests, though the larger the number of permutations, the longer it takes to calculate the values.</p>
</div>

<div><button id="run">Run</button></div>
<div id="plot"></div>

<script>

var xScale, yScale, xDomain, yDomain;

var height = 400;
var width = 400;
var padding = 30;

var svg = d3.select("#plot").append("svg")
.attr("height", height)
.attr("width", width);

var xScale = d3.scaleLinear().domain([-3, 3]).range([0, width]);
var yScale = d3.scaleLinear().domain([-3, 3]).range([height, 0]);

var xAxis = d3.axisBottom().scale(xScale);
svg.append("g")
  .attr("class", "axis")
  .attr("transform", "translate(0, " + (height / 2) + ")")
  .call(xAxis);

var yAxis = d3.axisLeft().scale(yScale);
svg.append("g")
        .attr("class", "axis")
        .attr("transform", "translate(" + (width / 2) + ", 0)")
        .call(yAxis);

var pValueText = svg.append("text").attr("x", xScale(2.7)).attr("y", yScale(2.5)).style("text-anchor", "end");
var permutationText = svg.append("text").attr("x", xScale(2.7)).attr("y", yScale(2.0)).style("text-anchor", "end");

var circles;

var threeDigits = d3.format(".3f");
var gaussian = d3.randomNormal();

// Generate fake data from a Gaussian linear model.
function generateLinear(n, slope, intercept, noise) {
	var points = [];
	
	for (var i = 0; i < n; i++) {
	    var x = gaussian();
	    // Deterministic part
	    var y = x * slope + intercept;
		// Random part
		y += noise * gaussian();
    
	    points.push( { x: x, y: y } );		
	}

	return points;
}

// Add a line to the plot based on a linear model
function drawLine(model, color, opacity) {
	svg.append("line")
	.attr("x1", xScale(-3))
	.attr("y1", yScale(model.slope * -3 + model.intercept))
	.attr("x2", xScale(3))
	.attr("y2", yScale(model.slope * 3 + model.intercept))
	.style("opacity", opacity)
	.style("stroke", color);
}

// Get a regression model from a set of x,y pairs and calculate the p-value from a t-test.
function getModel (activePoints) {	
	var model = {};

	var meanX = d3.mean(activePoints, function (d) { 
		return d.x;
	});

	var meanY = d3.mean(activePoints, function (d) { 
		return d.y;
	});

	var sumSquaredX = d3.sum(activePoints, function (d) {
		return (d.x - meanX) * (d.x - meanX);
	});
	
	// Set model parameters
	model.slope = d3.sum(activePoints, function (d) {
		return (d.x - meanX) * (d.y - meanY);
	});
	model.slope /= sumSquaredX;
	model.intercept = meanY - model.slope * meanX;
		
	// Add up the squared errors
	var sumSquaredErrors = d3.sum(activePoints, function (d) {
		var error = d.y - (model.slope * d.x + model.intercept);
		return error * error;
	});
	
	// Here's where we compute the statistic that we pass to the pValue function.
	model.standardError = Math.sqrt(sumSquaredErrors / ( (activePoints.length - 2) * sumSquaredX));
	model.p = (1.0 - pValue(Math.abs(model.slope) / model.standardError, activePoints.length - 2));
	
	return model;
}

// Carry out one iteration of a permutation test
function permute(points) {
	var permutedPoints = [];

	// [Part A] Create a new array of x,y pairs. The x values should be the same as 
	//  the x values in the input array "points", but the y values should be
	//  randomly shuffled.

	// Shuffle y values of points
	var shuffled = d3.shuffle( points.map(function (point) { return point.y; }) );
    
    // Create new array with permuted y values
    for (var i = 0; i < points.length; i++) {
        permutedPoints.push({
            x: points[i].x, y: shuffled[i]
        });
    }
	
	return permutedPoints;
}

// [Part G]
var less = 0;
var more = 0;
var totall = 0;
var totalm = 0;
var lvalue = {'n': 0, 'loop': 0};
var mvalue = {'n': 0, 'loop': 0};
// p-values < 0.05, slope = 0.02, noise = 0.3
/*for (var i = 1; i <= 1000; i++) { // n values
	for (var j = 1; j <= 30; j++) { // generate points
		var pts = generateLinear(i, 0.02, 0, 0.3);
	    var mod = getModel(pts);
	    //console.log(mod.p)

		if (threeDigits(mod.p) < 0.05) {
			less++;
		}
		totall++;

		if ((less/totall) > 0.75) {
			lvalue['n'] = i;
			lvalue['loop'] = j;
			break;
		}
	}
	
}
console.log(lvalue);

// p-values >= 0.05, slope = 0.2, noise = 0.3
for (var i = 0; i < 1500; i++) { // n values
	for (var j = 0; j < 10; j++) { // generate points
		var pts = generateLinear(i, 0.2, 0, 0.3);
	    var mod = getModel(pts);
	    //console.log(mod.p);

		if (threeDigits(mod.p) >= 0.05) {
			more++;
		}
		totalm++;

		if ((more/totalm) > 0.75) {
			mvalue['n'] = i;
			mvalue['loop'] = j;
			break;
		}
	}
	
}
console.log(mvalue);*/


function run() {
	var points = generateLinear(10, 0.1, 0, 0.3);
	//var points = generateLinear(100, 0.02, 0, 0.3);

	svg.selectAll("line").remove();

	circles = svg.selectAll("circle").data(points);
	
	circles = circles.enter().append("circle").merge(circles);

	circles
	.attr("cx", function (d) { return xScale(d.x); })
	.attr("cy", function (d) { return yScale(d.y); })
	.attr("r", 3).style("fill", "#99d8c9");

	var model = getModel(points);

	pValueText.text("p-value: " + threeDigits(model.p));

	drawLine(model, "#2ca25f", 0.5);

	var steeperSlopes = 0;
	var numPermutations = 200;

	// [Part B] Create 200 random permutations of the original data in the "points" array.
	// For each one, compute a linear model from that permuted data.
	//  Check whether the absolute value of the permuted-data slope is larger
	//   than the absolute value of the original-data slope.
	//  Set "steeperSlopes" equal to the total number of permutations
	//   for which this condition is true.

	for (var i = 0; i < numPermutations; i++) {
        // Create permutations of points
        var permuted = permute(points);

        // Compute linear model from permuted
        var newModel = getModel(permuted);
        drawLine(newModel, "#636363", .025);

        // Check if permuted slope is larger than original slope
        if (Math.abs(newModel.slope) > Math.abs(model.slope)) {
            steeperSlopes++;
        }
    }

	permutationText.text("permutation: " + threeDigits(0.5 * steeperSlopes / numPermutations));
	
	// [Part E] Add a point on the second plot with x equal to the p-value of
	//  the real-data model, and y equal to half the proportion of 
	//  permuted-data models with a steeper slope than the real-data model.

	svg2.append("circle")
	    .attr("cx", xScale2(model.p))
	    .attr("cy", yScale2(threeDigits(0.5 * steeperSlopes / numPermutations)))
	    .attr("r", 3)
	    .attr("fill", "black");

}
d3.select("#run").on("click", run);

// [Part D] Create a second SVG element with an x-axis for p-values and a y-axis
//   for permutation test values.
// Both scales should go from zero to one. Add a diagonal line from (0,0) to (0.5,0.5).

var svg2 = d3.select("#plot").append("svg")
    .attr("height", height)
    .attr("width", width);

// Define x and y scales
var xScale2 = d3.scaleLinear().domain([0, 1]).range([padding, width]);
var yScale2 = d3.scaleLinear().domain([0, 1]).range([height - padding, 0]);

// Create axes
svg2.append("g")
	.attr("class", "axis")
	.attr("transform", "translate(0, " + (height - padding) + ")")
	.call(d3.axisBottom(xScale2));
svg2.append("text")
    .attr("transform",
            "translate(" + (width/2) + " ," + 
                           (height + 10) + ")")
    .text("p-value");
svg2.append("g")
	.attr("class", "axis")
	.attr("transform", "translate(" + (padding) + ", 0)")
	.call(d3.axisLeft(yScale2));
svg2.append("text")
    .attr("transform", "rotate(-90)")
      .attr("y", 0)
      .attr("x",0 - (height / 2))
      .attr("text-anchor", "middle")
    .text("permutation");

// Add a line frp, (0,0) to (0.5, 0.5)
var line = svg2.append("line")
    .attr("x1", xScale2(0)).attr("x2", xScale2(0.5))
    .attr("y1", yScale2(0)).attr("y2", yScale2(0.5))
    .attr("stroke", "black");



// Here's some ugly statistics code. I don't expect anyone to understand 
//  what this is doing, but you're welcome to try!
// Also: it is not 1968. Never write code like this.
function pValue(t, df) {
  // JS translated from Java translated from C translated from FORTRAN
  //  originally published in a Stats Journal when LBJ was president:
  // ALGORITHM AS 3  APPL. STATIST. (1968) VOL.17, P.189
  // Computes P(T<t)
  var a,b,idf,im2,ioe,s,c,ks,fk,k;
  var g1=0.3183098862;// =1/pi;
  idf=df;
  a=t/Math.sqrt(idf);
  b=idf/(idf+t*t);
  im2=df-2;
  ioe=idf%2;
  s=1;
  c=1;
  idf=1;
  ks=2+ioe;
  fk=ks;
  if(im2>=2) {
    for(k=ks;k<=im2;k+=2) {
      c=c*b*(fk-1)/fk;
      s+=c;
      if(s!=idf) {
        idf=s;
        fk+=2;
      }
    }
  }
  if(ioe!=1)
    return 0.5+0.5*a*Math.sqrt(b)*s;
  if(df==1) s=0;
  return 0.5+(a*b*s+Math.atan(a))*g1;
}


</script>
</body>
</html>